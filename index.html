<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1200px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}


</style>


<html>
<head>
	<title>HAMLET: Graph Transformer Neural Operator for Partial Differential Equations</title>
	<meta property="og:image" content="./resources/teaser.pdf"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="HAMLET: Graph Transformer Neural Operator for Partial Differential Equations" />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
	<script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.js"></script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:32px">HAMLET: Graph Transformer Neural Operator for Partial Differential Equations</span>
		<br>
		<br>
		<table align=center width=1100px>
			<table align=center width=1100px>
				<tr>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="https://andreybryutkin.netlify.app">Andrey Bryutkin</a><sup>*1</sup></span>
						</center>
					</td>
					<td align=center width=180px>
						<center>
							<span style="font-size:18px"><a href="https://scholar.google.com.hk/citations?user=ap-tq8cAAAAJ&hl=zh-CN">Jiahao Huang</a><sup>*2</sup></span>
						</center>
					</td>
					<td align=center width=180px>
						<center>
							<span style="font-size:18px"><a href="https://zhongying-deng.github.io">Zhongying Deng</a><sup>3</sup></span>
						</center>
					</td>
					<td align=center width=180px>
						<center>
							<span style="font-size:18px"><a href="https://www.yanglab.fyi">Guang Yang</a><sup>2</sup></span>
						</center>
					</td>
					<td align=center width=250px>
						<center>
							<span style="font-size:18px"><a href="https://www.damtp.cam.ac.uk/user/cbs31/Home.html">Carola-Bibiane Schönlieb</a><sup>3</sup></span>
						</center>
					</td>
					<td align=center width=250px>
						<center>
							<span style="font-size:18px"><a href="https://angelicaiaviles.wordpress.com/">Angelica I. Aviles-Rivero</a><sup>3</sup></span>
						</center>
					</td>
				</tr>
			</table>			
			<br>
			<table align=center width=800px>
				<tr>
					<td align=center width=800px>
						<center>
							<span style="font-size:21px"><sup>1</sup>MIT&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <sup>2</sup> Imperial College London&emsp;&emsp;&emsp;&emsp;&emsp;  <sup>3</sup> University of Cambridge  </span><br/>
							<img width="750" src="./resources/logos.png" alt="affiliations">
							<span style="font-size:21px"><sup>*</sup>Equal contribution </span><br/>
						</center>
					</td>
				</tr>
			</table>
			<br>
			<table align=center width=800px>
				<tr>
					<td align=center width=200px>
						<center>
							<span style="font-size:24px"><a href='https://doi.org/10.48550/arXiv.2402.03541'>[Paper]</a></span>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=560px>
					<center>
						<img class="round" style="width:650px" src="./resources/teaser.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=950px>
			<tr>
				<td>
					This is a website made for <a href='https://doi.org/10.48550/arXiv.2402.03541'>HAMLET: Graph Transformer Neural Operator for Partial Differential Equations</a>. 
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=900px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				We present a novel graph transformer framework, HAMLET, designed to address the challenges in solving partial differential equations (PDEs) using neural networks. The framework uses graph transformers with modular input encoders to directly incorporate differential equation information into the solution process. This modularity enhances parameter correspondence control, making HAMLET adaptable to PDEs of arbitrary geometries and varied input formats. Notably, HAMLET scales effectively with increasing data complexity and noise, showcasing its robustness. HAMLET is not just tailored to a single type of physical simulation, but can be applied across various domains. Moreover, it boosts model resilience and performance, especially in scenarios with limited data. We demonstrate, through extensive experiments, that our framework is capable of outperforming current techniques for PDEs.			</td>
		</tr>
	</table>
	<br>



	<hr>

	<center><h1>Network</h1></center>
	<table align=center width=800px>
		<tr>
			<td align=center width=700px>
				<center>
					<img src="resources/network.png" style="width:100%">


				</center>
			</td>
		</tr>
	</table>
	<table align=center width=800px>
		<center>
			<tr>
				<center><td>
					<!-- Architectural overview of HAMLET. -->
				</td></center>
			</tr>
		</center>
	</table>

	<hr>

	<center><h1>Experiments</h1></center>
	<table align=center width=800px>
		<tr>
			<td align=center width=700px>
				<center>
					<img src="resources/result1.png" style="width:100%">
					<br>
					<br>
					<br>										
					<img src="resources/result2.png" style="width:100%">
					<br>
					<br>
					<br>										
					<img src="resources/result3.png" style="width:100%">
				</center>
			</td>
		</tr>
	</table>


	<br>
	<hr>

	<table align=center width=800px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=“https://doi.org/10.48550/arXiv.2402.03541"><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt"><br>Andrey Bryutkin*, Jiahao Huang*, Zhongying Deng, Guang Yang, Carola-Bibiane Schönlieb, Angelica I Aviles-Rivero.<br>
				<b>HAMLET: Graph Transformer Neural Operator for Partial Differential Equations</b><br>
				(hosted on <a href="https://doi.org/10.48550/arXiv.2402.03541">ArXiv</a>)<br>
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=920px>
		<tr>
			<td width=420px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					AB was supported in part by the Akamai Presidential Fellowship and the Hans-Messer Foundation. 
					JH and GY was supported in part by the ERC IMI (101005122), the H2020 (952172), the MRC (MC/ PC/21013), the Royal Society (IEC NSFC211235), the NVIDIA Academic Hardware Grant Program, the SABER project supported by Boehringer Ingelheim Ltd, Wellcome Leap Dynamic Resilience, and the UKRI Future Leaders Fellowship (MR/V023799/1). 
					CBS acknowledges support from the Philip Leverhulme Prize, the Royal Society Wolfson Fellowship, the EPSRC advanced career fellowship EP/V029428/1, EPSRC grants EP/S026045/1 and EP/T003553/1, EP/N014588/1, EP/T017961/1, the Wellcome Innovator Awards 215733/Z/19/Z and 221633/Z/20/Z, CCMI and the Alan Turing Institute. 
					AAR gratefully acknowledges funding from the Cambridge Centre for Data-Driven Discovery and Accelerate Programme for Scientific Discovery, made possible by a donation from Schmidt Futures, ESPRC Digital Core Capability Award, and CMIH and CCIMI, University of Cambridge.

				
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>
